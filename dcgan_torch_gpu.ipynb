{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim\n",
    "from torchvision.utils import save_image #保存图片\n",
    "from torchvision.datasets import CIFAR10,MNIST #下载图片数据集\n",
    "from torch.utils.data import DataLoader #读取批次\n",
    "import torchvision.transforms as transforms #张量转换\n",
    "from torch.autograd import Variable\n",
    "import time #计时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "tensor([6, 9, 8, 9, 5, 3, 1, 6, 0, 1, 5, 3, 1, 4, 7, 9, 2, 7, 6, 0, 7, 3, 9, 4,\n",
      "        4, 7, 5, 2, 9, 8, 8, 9, 2, 8, 8, 2, 8, 2, 5, 5, 0, 6, 0, 5, 7, 5, 3, 3,\n",
      "        4, 5, 7, 9, 5, 5, 3, 9, 9, 4, 3, 5, 6, 5, 1, 8])\n"
     ]
    }
   ],
   "source": [
    "# 读取数据集\n",
    "dataset = MNIST(\n",
    "    root='./data', train=True, transform = transforms.ToTensor(), download = True\n",
    ")\n",
    "# dataset = CIFAR10(root = './data', \n",
    "#                  download = True, transform = transforms.ToTensor()) #下载数据集\n",
    "dataloader = DataLoader(dataset, batch_size= 64, shuffle= True)      # 按批次读取数据(一批64张，总共有50000张，所以有50000/64=781批)，shuffle= True打乱数据\n",
    "#### 查看数据 ####\n",
    "a = iter(dataloader)\n",
    "print(next(a)[0].shape)\n",
    "print(next(a)[1])   # 标签\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  (1): LeakyReLU(negative_slope=0.2)\n",
      "  (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (4): LeakyReLU(negative_slope=0.2)\n",
      "  (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (7): LeakyReLU(negative_slope=0.2)\n",
      "  (8): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 构建判别网络\n",
    "n_d_feature = 64 # 潜在大小\n",
    "n_channel = 1 # 输入通道数\n",
    "dnet = nn.Sequential(\n",
    "        nn.Conv2d(n_channel, n_d_feature, kernel_size=4,\n",
    "                 stride=2, padding=1),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(n_d_feature, 2 * n_d_feature, kernel_size=4,\n",
    "                 stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(2 * n_d_feature),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(2 * n_d_feature, 4 * n_d_feature, kernel_size=4,\n",
    "                 stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(4 * n_d_feature),\n",
    "        nn.LeakyReLU(0.2),\n",
    "        nn.Conv2d(4 * n_d_feature, 1, kernel_size=3)).cuda()\n",
    "print(dnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): ConvTranspose2d(64, 256, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "  (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU()\n",
      "  (3): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (5): ReLU()\n",
      "  (6): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (8): ReLU()\n",
      "  (9): ConvTranspose2d(64, 1, kernel_size=(2, 2), stride=(2, 2), padding=(2, 2))\n",
      "  (10): Tanh()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 构建生成网络\n",
    "latent_size = 64 # 输入通道数\n",
    "n_g_feature = 64 # 输出通道数\n",
    "\n",
    "gnet = nn.Sequential(\n",
    "        nn.ConvTranspose2d(latent_size, 4 * n_g_feature, kernel_size=4,\n",
    "                          bias=False),\n",
    "        nn.BatchNorm2d(4 * n_g_feature),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(4 * n_g_feature, 2 * n_g_feature, kernel_size=4,\n",
    "                          stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(2 * n_g_feature),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(2 * n_g_feature, n_g_feature, kernel_size=4,\n",
    "                          stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(n_g_feature),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(n_g_feature, n_channel, kernel_size=2,\n",
    "                          stride=2, padding=2),\n",
    "        nn.Tanh()).cuda()\n",
    "print(gnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (1): LeakyReLU(negative_slope=0.2)\n",
       "  (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (4): LeakyReLU(negative_slope=0.2)\n",
       "  (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "  (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (7): LeakyReLU(negative_slope=0.2)\n",
       "  (8): Conv2d(256, 1, kernel_size=(3, 3), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 网络初始化\n",
    "import torch.nn.init as init\n",
    "def weights_init(m):\n",
    "    if type(m) in [nn.ConvTranspose2d, nn.Conv2d]:\n",
    "        init.xavier_normal_(m.weight)       # 指定模型权重进行赋值“用一个均匀分布生成值，填充输入的张量或变量”\n",
    "    elif type(m) == nn.BatchNorm2d:\n",
    "        init.normal_(m.weight, 1.0, 0.02)   # 从给定均值和标准差的正态分布N(mean, std)中生成值，填充输入的张量或变量\n",
    "        init.constant_(m.bias, 0)\n",
    "        \n",
    "gnet.apply(weights_init)\n",
    "dnet.apply(weights_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数解释\n",
    "- torch.load('xxx.pth', map_location=lambda storage, loc: storage.cuda(0))：如果当初保存参数的时候是保存的cpu的参数，那么需要加载到GPU上则需要使用map_location来进行转化。\n",
    "- torch.load('xxx.pth', map_location=lambda storage, loc: storage): 原本保存参数在GPU上，现在需要加载到CPU上。\n",
    "- torch.load('xxx.pth', map_location={'cuda:1':'cuda:0'}): 原本保存参数在GPU1上，现在需要加载到GPU0上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 载入cpu训练的预参数\n",
    "# checkpoint_d = torch.load('discriminator.pth', map_location=lambda storage, loc: storage.cuda(0))\n",
    "# checkpoint_g = torch.load('generator.pth', map_location=lambda storage, loc: storage.cuda(0))\n",
    "# dnet.load_state_dict(checkpoint_d)\n",
    "# gnet.load_state_dict(checkpoint_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#载入gpu训练的预参数\n",
    "#checkpoint_d = torch.load('D.pth')\n",
    "#checkpoint_g = torch.load('G.pth')\n",
    "#dnet.load_state_dict(checkpoint_d)\n",
    "#gnet.load_state_dict(checkpoint_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失\n",
    "criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "#定义优化器\n",
    "goptimizer = torch.optim.Adam(gnet.parameters(),\n",
    "                             lr=0.0002, betas=(0.5, 0.999))\n",
    "doptimizer = torch.optim.Adam(dnet.parameters(),\n",
    "                             lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成固定的噪音数据，输入到G网络的数据，用于检测生成网络的结果\n",
    "batch_size = 64\n",
    "fixed_noise = torch.randn(batch_size, latent_size, 1, 1).cuda()\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/5][0/938]鉴别器G损失:1.84623 生成器D损失：0.833955 真数据判真比例：0.282376 假数据判真比例：0.343563/0.46929\n",
      "[0/5][300/938]鉴别器G损失:0.333063 生成器D损失：4.23638 真数据判真比例：0.958263 假数据判真比例：0.235754/0.0183889\n",
      "[0/5][600/938]鉴别器G损失:0.370077 生成器D损失：1.88758 真数据判真比例：0.748114 假数据判真比例：0.0530615/0.175519\n",
      "[0/5][900/938]鉴别器G损失:0.581111 生成器D损失：2.13298 真数据判真比例：0.939526 假数据判真比例：0.350107/0.159948\n",
      "[1/5][0/938]鉴别器G损失:0.244237 生成器D损失：4.05243 真数据判真比例：0.98002 假数据判真比例：0.193074/0.0204833\n",
      "[1/5][300/938]鉴别器G损失:0.774482 生成器D损失：1.68781 真数据判真比例：0.611245 假数据判真比例：0.159228/0.21547\n",
      "[1/5][600/938]鉴别器G损失:0.130119 生成器D损失：3.45207 真数据判真比例：0.954396 假数据判真比例：0.0773588/0.0388486\n",
      "[1/5][900/938]鉴别器G损失:0.247125 生成器D损失：3.65967 真数据判真比例：0.944922 假数据判真比例：0.159891/0.0342356\n",
      "[2/5][0/938]鉴别器G损失:0.206971 生成器D损失：3.56086 真数据判真比例：0.960546 假数据判真比例：0.145074/0.0368723\n",
      "[2/5][300/938]鉴别器G损失:0.166749 生成器D损失：3.16513 真数据判真比例：0.889824 假数据判真比例：0.0433403/0.0552686\n",
      "[2/5][600/938]鉴别器G损失:0.882025 生成器D损失：2.01287 真数据判真比例：0.776345 假数据判真比例：0.379883/0.171522\n",
      "[2/5][900/938]鉴别器G损失:0.199809 生成器D损失：3.12645 真数据判真比例：0.960825 假数据判真比例：0.137861/0.0590429\n",
      "[3/5][0/938]鉴别器G损失:0.813941 生成器D损失：4.38052 真数据判真比例：0.987348 假数据判真比例：0.488068/0.0179564\n",
      "[3/5][300/938]鉴别器G损失:0.17399 生成器D损失：3.47926 真数据判真比例：0.914013 假数据判真比例：0.0699256/0.0527741\n",
      "[3/5][600/938]鉴别器G损失:0.062101 生成器D损失：4.64035 真数据判真比例：0.960537 假数据判真比例：0.0205639/0.0138876\n",
      "[3/5][900/938]鉴别器G损失:0.185356 生成器D损失：3.20241 真数据判真比例：0.905778 假数据判真比例：0.0749324/0.0568628\n",
      "[4/5][0/938]鉴别器G损失:0.223985 生成器D损失：2.26124 真数据判真比例：0.853493 假数据判真比例：0.0485791/0.136872\n",
      "[4/5][300/938]鉴别器G损失:0.43528 生成器D损失：1.79596 真数据判真比例：0.705843 假数据判真比例：0.0135165/0.226084\n",
      "[4/5][600/938]鉴别器G损失:0.147275 生成器D损失：4.21724 真数据判真比例：0.974284 假数据判真比例：0.107927/0.0222272\n",
      "[4/5][900/938]鉴别器G损失:0.0820039 生成器D损失：3.68875 真数据判真比例：0.959724 假数据判真比例：0.0369203/0.0435286\n",
      "2.4830039580663046\n"
     ]
    }
   ],
   "source": [
    "#开始训练\n",
    "start = time.time() #开始时间\n",
    "\n",
    "epoch_num = 5#共训练5个周期\n",
    "for epoch in range(epoch_num):\n",
    "    for batch_idx, data in enumerate(dataloader):\n",
    "        real_images, _ = data\n",
    "        batch_size = real_images.shape[0]\n",
    "        #训练判别器D\n",
    "        labels = torch.ones(batch_size) # 真实数据的标签：1\n",
    "        preds = dnet(Variable(real_images.type(Tensor))) #将真实数据喂给D网络\n",
    "        outputs = preds.reshape(-1) # 转换成(batch_size,)维度\n",
    "        dloss_real = criterion(outputs, labels.type(Tensor))\n",
    "        dmean_real = outputs.sigmoid().mean() #计算判别器将多少真数据判别为真，仅用于输出显示\n",
    "        \n",
    "        noises = torch.randn(batch_size, latent_size, 1, 1) # [64, 64, 1, 1]\n",
    "        fake_images = gnet(noises.type(Tensor)) # 生成假数据[64, 1, 28, 28]\n",
    "        labels = torch.zeros(batch_size)    # 生成假数据的标签：0\n",
    "        fake = fake_images.detach()     # 消除梯度,其实可以不用，因为最后更新的只是dnet的参数\n",
    "        preds = dnet(fake)              # 将假数据喂给判别器\n",
    "        outputs = preds.reshape(-1)     # 转换成(batch_size,)维度\n",
    "        dloss_fake = criterion(outputs.type(Tensor), labels.type(Tensor))\n",
    "        dmean_fake = outputs.sigmoid().mean() # 计算判别器将多少假数据判断为错的，仅用于输出显示\n",
    "        \n",
    "        dloss = dloss_real + dloss_fake #总的鉴别器损失为两者之和\n",
    "        dnet.zero_grad()    # 梯度清零\n",
    "        dloss.backward()    # 反向传播\n",
    "        doptimizer.step()\n",
    "        \n",
    "        #训练生成器G\n",
    "        labels = torch.ones(batch_size) # 在训练生成器G时，希望生成器的标签为1\n",
    "        preds = dnet(fake_images)   # 让假数据通过鉴别网络\n",
    "        outputs = preds.reshape(-1) # 转换成(batch_size,)维度\n",
    "        gloss = criterion(outputs.type(Tensor), labels.type(Tensor))\n",
    "        gmean_fake = outputs.sigmoid().mean() # 计算判别器将多少假数据判断为真，仅用于输出显示\n",
    "        \n",
    "        gnet.zero_grad()    # 梯度清零\n",
    "        gloss.backward()    # 反向传播\n",
    "        goptimizer.step()\n",
    "        \n",
    "        #输出本步训练结果\n",
    "        # print('[{}/{}]'.format(epoch, epoch_num) + '[{}/{}]'.format(batch_idx, len(dataloader)) +\n",
    "        #      '鉴别器G损失:{:g} 生成器D损失：{:g}'.format(dloss, gloss) + \n",
    "        #      '真数据判真比例：{:g} 假数据判真比例：{:g}/{:g}'.format(dmean_real, dmean_fake, gmean_fake))\n",
    "        if batch_idx % 300 == 0:\n",
    "            print('[{}/{}]'.format(epoch, epoch_num) + '[{}/{}]'.format(batch_idx, len(dataloader)) +\n",
    "             '鉴别器G损失:{:g} 生成器D损失：{:g} '.format(dloss, gloss) + \n",
    "             '真数据判真比例：{:g} 假数据判假比例：{:g}，假数据判真比例：{:g}'.format(dmean_real, dmean_fake, gmean_fake))\n",
    "            fake = gnet(fixed_noise) # 利用噪声生成假数据\n",
    "            path = './dcgan_img/gpu{:02d}_batch{:03d}.png'.format(epoch, batch_idx)\n",
    "            save_image(fake, path, normalize=False)\n",
    "            \n",
    "end = time.time()\n",
    "print((end - start)/60) #输出结束时间(单位：分钟)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dnet.state_dict(),'./dcgan_discriminator.pth')\n",
    "torch.save(gnet.state_dict(),'./dcgan_generator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
